#!/usr/bin/env python3

###########################################################################
# Builds a local copy of the FAC database
#
# Last revision: 08/10/2017
#
# Authors:
#   P. Kevin Bohan <votiputox@gmail.com>
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.
###########################################################################

from pyvirtualdisplay import Display
from selenium import webdriver
from selenium.webdriver.common.desired_capabilities import DesiredCapabilities
from selenium.webdriver.common.keys import Keys
from selenium.common.exceptions import TimeoutException
from selenium.webdriver.support.ui import Select
from bs4 import BeautifulSoup
import NIOD
import argparse
import datetime
import sys


##########
# Globals
##########

date_format = '%Y-%m-%d'
fac_epoch   = '2010-01-01'
today       = datetime.datetime.today()


####################
# Set some defaults
####################

target_url = 'https://harvester.census.gov/facdissem/SearchA133.aspx'
target_dir = '.'
timeout    = 10


###############################
# Helper: Select a web control
###############################

def open_tag(driver, css_selector):
    driver.find_element_by_css_selector(css_selector).click()


####################################
# Helper: Input text into a control
####################################

def enter_in_tag(driver, css_selector, text):
    driver.find_element_by_css_selector(css_selector).send_keys(text)


#######################################
# Helper: See if a checkbox is checked
#######################################

def is_checked(driver, css_selector):
    element = driver.find_element_by_css_selector(css_selector)
    return element.is_selected()


###################################################
# Helper: Figure out what a given state's index is
###################################################

def get_state_element_id(driver, state):
    element = driver.find_element_by_xpath("//input[@value='" + state.get_abbrev() + "']")
    return '#' + element.get_attribute("id")
    
    
######################################
# Download a set of audit report PDFs
######################################

def fetch_from_fac(url, st, begin_date, end_date, dir):
    # Use Google Chrome
    drv = webdriver.Chrome()
    
    # Set up the virtual display
    display = Display(visible=0, size=(2048, 2048))
    display.start()

    # Fetch the top-level page
    try:
        drv.get(url)
    except Exception as e:
        print(str(e))
        sys.exit()
        
    # Click on "GENERAL INFORMATION"
    open_tag(drv, '#ui-id-1')

    # Figure out the index of the start year (assume current year is 1)
    idx_begin = (today.year % begin_date.year) + 1
    idx_end = (today.year % end_date.year) + 1
    
    # Uncheck 'All Years'
    open_tag(drv, '#MainContent_UcSearchFilters_FYear_CheckableItems_0')

    # Check applicable years
    for idx in range(idx_end, (idx_begin + 1)):
        css_id = '#MainContent_UcSearchFilters_FYear_CheckableItems_' + str(idx)
        open_tag(drv, css_id)

        if is_checked(drv, css_id) == False:
            enter_in_tag(drv, css_id, Keys.DOWN)
            open_tag(drv, css_id)
            
    # Fill out start and end dates
    fmt_start = begin_date.strftime('%m/%d/%Y')
    fmt_end = end_date.strftime('%m/%d/%Y')
    
    enter_in_tag(drv, "#MainContent_UcSearchFilters_DateProcessedControl_FromDate", fmt_start)
    enter_in_tag(drv, "#MainContent_UcSearchFilters_DateProcessedControl_ToDate", fmt_end)

    # Check the state that matches the requested index
    box_id = '#MainContent_UcSearchFilters_AuditeeState_ItemBox'
    css_id = get_state_element_id(drv, st)
    open_tag(drv, css_id)
    while is_checked(drv, css_id) == False:
        enter_in_tag(drv, box_id, Keys.DOWN)
        open_tag(drv, css_id)

    # Submit the form
    open_tag(drv, '#MainContent_UcSearchFilters_btnSearch_top')

    # Click through the disclosure page
    open_tag(drv, '#chkAgree')
    open_tag(drv, '#btnIAgree')

    # Select audits to download
    rpts_drop = Select(drv.find_element_by_css_selector('#MainContent_ucA133SearchResults_ddlAvailZipTop'))
    rpts_html = drv.find_element_by_css_selector('#MainContent_ucA133SearchResults_ddlAvailZipTop').get_attribute("innerHTML")

    bs = BeautifulSoup(rpts_html, "html.parser")
    laudit_tags = bs.findAll("option")
    laudit = []

    for option in laudit_tags:
        if option["value"].startswith("Audit Reports"):
            laudit.append(option["value"])
            
    if len(laudit) == 0:
        # SYSLOG
        print("audit reports list is not produced")
    else:
        # in this for loop we are selecting by groups of 100
        for audit in laudit:
            rpts_drop.select_by_visible_text(audit)
            # now we click on Download Audits button
            open_tag(drv, '#MainContent_ucA133SearchResults_btnDownloadZipTop')
            print('Downloading ' + audit)                                       
    
    # Clean up
    drv.close()
    display.stop()


###########################
# Configure the CLI Parser
###########################

parser = argparse.ArgumentParser(description='FAC Repository Builder', add_help=True)

# Be quiet (suppress all output)
parser.add_argument('-q',
                    '--quiet',
                    action='store_true',
                    default=False,
                    help="Suppress all output (suitable for cron)")

# Set the start date
parser.add_argument('-s',
                    '--start',
                    action='store',
                    default=fac_epoch,
                    help='The start date, in format YYYY-MM-DD')

# Set the end date
parser.add_argument('-e',
                    '--end',
                    action='store',
                    default=today.strftime(date_format),
                    help='The end date, in format YYYY-MM-DD')

# Set the target directory for PDF storage
parser.add_argument('-d',
                    '--dir',
                    action='store',
                    default=target_dir,
                    help='The directory to save PDFs to')

# Allow the user to specify a non-default URL
parser.add_argument('-u',
                    '--url',
                    action='store',
                    default=target_url,
                    help='The top-level URL to connect to')

cli = parser.parse_args()


#############################
# Download the audit reports
#############################

start_date = datetime.datetime.strptime(cli.start, '%Y-%m-%d')
end_date = datetime.datetime.strptime(cli.end, '%Y-%m-%d')

states = NIOD.State.get_all()

    
s = NIOD.State.find_by_abbrev('OR')
fetch_from_fac(cli.url, s, start_date, end_date, cli.dir)
